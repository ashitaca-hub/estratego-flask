name: DB – Explore schema & joinability (prematch prep)

on:
  workflow_dispatch:
    inputs:
      years_back:
        description: "Años hacia atrás para conteo en fs_matches_long"
        required: true
        default: "5"
      sample_limit:
        description: "Filas de muestra por consulta"
        required: true
        default: "50"
      tournament_search:
        description: "Filtro opcional p.ej. 'Zagreb' (para buscar en nombres de torneo)"
        required: false
        default: "Zagreb"

jobs:
  explore:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      YEARS_BACK: ${{ inputs.years_back }}
      SAMPLE_LIMIT: ${{ inputs.sample_limit }}
      T_SEARCH: ${{ inputs.tournament_search }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install PostgreSQL client
        run: sudo apt-get update && sudo apt-get install -y postgresql-client

      - name: Sanity – psql connectivity
        run: psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "select now();"

      - name: Ensure helper norm_tourney(txt) (no DROP)
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 <<'SQL'
          CREATE OR REPLACE FUNCTION public.norm_tourney(txt text)
          RETURNS text LANGUAGE sql IMMUTABLE AS $$
            SELECT regexp_replace(lower(coalesce(txt,'')), '\s+', ' ', 'g')
          $$;
          SQL

      - name: Prepare output folder
        run: mkdir -p /tmp/db_explore

      # ---------- 1) SCHEMA DUMPS ----------
      - name: Export schema columns (public, estratego_v1) → CSV
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\copy (
            SELECT table_schema, table_name, column_name, data_type, is_nullable, ordinal_position
            FROM information_schema.columns
            WHERE table_schema IN ('public','estratego_v1')
            ORDER BY table_schema, table_name, ordinal_position
          ) TO STDOUT WITH CSV HEADER" > /tmp/db_explore/schema_columns.csv

      - name: Columns presence for fs_matches_long (surface / speed_bucket)
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\copy (
            SELECT
              'fs_matches_long' AS table_name,
              MAX( (column_name='surface')::int )       AS has_surface_col,
              MAX( (column_name='speed_bucket')::int )  AS has_speed_bucket_col
            FROM information_schema.columns
            WHERE table_schema='public' AND table_name='fs_matches_long'
          ) TO STDOUT WITH CSV HEADER" > /tmp/db_explore/fs_columns_presence.csv

      # ---------- 2) SAMPLES & COUNTS ----------
      - name: Sample rows – fs_matches_long → CSV
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\copy (
            SELECT *
            FROM public.fs_matches_long
            ORDER BY match_date DESC NULLS LAST
            LIMIT ${SAMPLE_LIMIT}
          ) TO STDOUT WITH CSV HEADER" > /tmp/db_explore/fs_matches_long_sample.csv

      - name: Counts by year – fs_matches_long → CSV
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\copy (
            SELECT extract(year from match_date)::int AS year, COUNT(*) AS n
            FROM public.fs_matches_long
            WHERE match_date >= (current_date - interval '${YEARS_BACK} years')
            GROUP BY 1 ORDER BY 1
          ) TO STDOUT WITH CSV HEADER" > /tmp/db_explore/fs_counts_by_year.csv

      # ---------- 3) TOURNAMENT MAPS ----------
      - name: Distinct tournaments – fs_matches_long (top N) → CSV
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\copy (
            SELECT public.norm_tourney(tournament_name) AS key,
                   tournament_name,
                   COUNT(*) AS n
            FROM public.fs_matches_long
            GROUP BY 1,2
            ORDER BY n DESC NULLS LAST
            LIMIT ${SAMPLE_LIMIT}
          ) TO STDOUT WITH CSV HEADER" > /tmp/db_explore/fs_tournaments_top.csv

      - name: Distinct tournaments – estratego_v1.tournaments (top N by key dup) → CSV
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\copy (
            SELECT public.norm_tourney(name) AS key,
                   name,
                   level,
                   COUNT(*) OVER (PARTITION BY public.norm_tourney(name)) AS dup_key_ct
            FROM estratego_v1.tournaments
            ORDER BY dup_key_ct DESC NULLS LAST
            LIMIT ${SAMPLE_LIMIT}
          ) TO STDOUT WITH CSV HEADER" > /tmp/db_explore/et_tournaments_top.csv

      - name: Join by normalized name (rough map fs ↔ et) → CSV
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\copy (
            WITH fs AS (
              SELECT public.norm_tourney(tournament_name) AS key,
                     tournament_name,
                     COUNT(*) AS fs_n
              FROM public.fs_matches_long
              GROUP BY 1,2
            ),
            et AS (
              SELECT public.norm_tourney(name) AS key,
                     name AS et_name,
                     level,
                     tourney_id
              FROM estratego_v1.tournaments
            )
            SELECT fs.key, fs.tournament_name, et.et_name, et.level, et.tourney_id, fs.fs_n
            FROM fs
            LEFT JOIN et USING (key)
            ORDER BY fs.fs_n DESC NULLS LAST, fs.key
          ) TO STDOUT WITH CSV HEADER" > /tmp/db_explore/join_fs_et_by_key.csv

      # ---------- 4) LOOKUP SEARCH TERM ----------
      - name: Lookup term in fs_matches_long (ILIKE) → CSV
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\copy (
            SELECT DISTINCT tournament_name
            FROM public.fs_matches_long
            WHERE tournament_name ILIKE ${'$'}$${T_SEARCH}${'$'}$
            ORDER BY 1
          ) TO STDOUT WITH CSV HEADER" > /tmp/db_explore/fs_lookup_term.csv

      - name: Lookup term in estratego_v1.tournaments (ILIKE) → CSV
        run: |
          psql "$DATABASE_URL" -v ON_ERROR_STOP=1 -c "\copy (
            SELECT tourney_id, name, level
            FROM estratego_v1.tournaments
            WHERE name ILIKE ${'$'}$${T_SEARCH}${'$'}$
            ORDER BY name
          ) TO STDOUT WITH CSV HEADER" > /tmp/db_explore/et_lookup_term.csv

      # ---------- 5) UPLOAD ARTIFACT ----------
      - name: Upload CSV artifact
        uses: actions/upload-artifact@v4
        with:
          name: db_explore_outputs
          path: /tmp/db_explore
          retention-days: 7
